{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b12b0-a8d9-4e34-8130-6f13838fc81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Desccire the pucpose and renejits oj pooling in CNN\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c5e7c-b250-4464-a41e-e56ae9ee74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pooling, specifically MaxPooling and AveragePooling, is a crucial operation in Convolutional Neural Networks (CNNs) used for image recognition and other tasks involving grid-like data such as spectrograms or sensor data. Pooling plays a role in reducing the spatial dimensions of the input while retaining important features, ultimately aiding in feature extraction and model efficiency.\n",
    "\n",
    "Purpose of Pooling:\n",
    "\n",
    "Dimension Reduction: Pooling reduces the spatial dimensions of the feature maps, making subsequent computations faster and more memory-efficient. This is important because as the network goes deeper, the spatial dimensions tend to decrease due to convolutions, and pooling helps manage this reduction.\n",
    "\n",
    "Translation Invariance: Pooling helps create a degree of translation invariance in the learned features. This means that if an object or feature is slightly shifted within an image, the pooled representation remains relatively stable. This can make the network more robust to small variations in input.\n",
    "\n",
    "Feature Learning: By pooling, the network focuses on the most prominent features within a local region of the input. This can help in capturing important patterns, edges, or textures that are more resilient to small changes.\n",
    "\n",
    "Types of Pooling:\n",
    "\n",
    "Max Pooling: In max pooling, for each local region (pooling window) in the feature map, the maximum value is taken as the representative feature for that region. Max pooling is particularly effective at capturing dominant features and edges within the region.\n",
    "\n",
    "Average Pooling: In average pooling, the average value of the elements in the local region is computed. This can be useful for creating a more smoothed representation of the input, which might be helpful for certain tasks.\n",
    "\n",
    "Relevance and Limitations:\n",
    "\n",
    "Loss of Spatial Information: While pooling is effective for dimension reduction and feature extraction, it comes at the cost of losing some spatial information. This loss can be acceptable to some extent, as higher-level layers in the network are responsible for capturing more abstract and complex features.\n",
    "\n",
    "Pooling Size and Stride: The size of the pooling window and the stride (how much the window moves between pooling operations) affect the degree of dimension reduction and translation invariance. Smaller pooling windows and strides can help retain more spatial information but might lead to more computations.\n",
    "\n",
    "Recent Trends: In more recent CNN architectures, there has been a shift towards using smaller or even no pooling layers, relying on strides and convolutional layers to achieve similar effects. This is particularly true for tasks like object detection and semantic segmentation, where precise spatial information is important.\n",
    "\n",
    "In summary, pooling is a technique in Convolutional Neural Networks that serves to reduce the spatial dimensions of feature maps while retaining important information for feature extraction and computational efficiency. It plays a significant role in creating translation invariance and aiding in the extraction of dominant features. However, its use and necessity have evolved over time based on the architecture and task at hand.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a216d-5a9d-4039-aaf0-12be65344961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Explain the dijjecence retween Xin pooling and Xax poolingp\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85db50-ef23-44a1-872d-f338cdffff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   It seems like there might be a typographical error in your question, but I'll try to decipher it and provide an explanation for both \"Xin pooling\" and \"Xax pooling.\" If you meant \"Max pooling\" and \"Average pooling,\" then I'll go ahead and explain the differences between these two types of pooling in Convolutional Neural Networks (CNNs).\n",
    "\n",
    "Max Pooling:\n",
    "Max pooling is a pooling operation commonly used in CNNs. In max pooling, a pooling window (usually a small matrix) slides over the input feature map, and for each local region covered by the window, the maximum value within that region is selected. This maximum value becomes the representative feature for that region in the pooled feature map.\n",
    "\n",
    "Advantages of Max Pooling:\n",
    "\n",
    "Max pooling is effective at capturing the most prominent features and edges within a local region.\n",
    "It helps create translation invariance by focusing on the most significant feature in the region, which can help the network recognize features regardless of their exact location.\n",
    "Disadvantages of Max Pooling:\n",
    "\n",
    "Max pooling discards all information about the non-maximum values within a region, potentially leading to loss of fine-grained details.\n",
    "It doesn't provide any information about the average or overall intensity of the features in the region.\n",
    "Average Pooling:\n",
    "Average pooling is another pooling operation used in CNNs. Similar to max pooling, a pooling window slides over the input feature map, but instead of selecting the maximum value, the average value of all the elements within the region covered by the window is computed. This average value becomes the representative feature for that region in the pooled feature map.\n",
    "\n",
    "Advantages of Average Pooling:\n",
    "\n",
    "Average pooling provides a smoothed representation of the input, which can be useful for reducing noise and creating a more generalized view of the features.\n",
    "It retains more information about the overall distribution of features within a region compared to max pooling.\n",
    "Disadvantages of Average Pooling:\n",
    "\n",
    "Average pooling might not be as effective at capturing sharp edges or distinct features as max pooling, particularly in scenarios where specific features need to be highlighted.\n",
    "In summary, the main difference between max pooling and average pooling lies in the way they aggregate information within a local region of the input feature map. Max pooling selects the maximum value, emphasizing dominant features, while average pooling computes the average value, providing a more smoothed representation. The choice between these two pooling methods depends on the specific task and the desired properties of the pooled feature map.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d5892-7c49-4389-84aa-5aabff28101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Discuss the concept oj padding in CNN and its signijicancep\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27633f4-c2b0-402b-ab69-a0bba6a4ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Padding is a fundamental concept in Convolutional Neural Networks (CNNs) that involves adding extra pixels or values to the input data before applying convolutional operations. Padding is primarily used to control the spatial dimensions of the output feature maps after convolution and to preserve important information at the borders of the input.\n",
    "\n",
    "In a CNN, convolutional layers slide a set of filters (also called kernels) over the input data to extract features. During this process, the filters scan the input data, and their receptive fields determine the size of the output feature maps. Padding can be applied to modify this process. There are two main types of padding:\n",
    "\n",
    "Valid (Zero Padding): In this type of padding, no extra pixels are added to the input data. As the filters slide over the input, they only consider positions where the entire filter can fit within the input without exceeding its boundaries. This results in a smaller output feature map compared to the input. Valid padding is useful when you want to reduce the spatial dimensions of the output feature maps.\n",
    "\n",
    "Same (Zero-Centered Padding): In same padding, extra pixels (usually zeros) are added around the input data so that the filters can slide over the input while preserving its spatial dimensions. Specifically, the amount of padding added is determined by the size of the filter. The goal of same padding is to ensure that the output feature map has the same spatial dimensions as the input. This is particularly important for maintaining information at the borders of the input, which would otherwise be lost due to the filter moving over the input.\n",
    "\n",
    "Significance of Padding:\n",
    "\n",
    "Preservation of Spatial Information: Padding helps preserve the spatial information at the borders of the input data. Without padding, convolutional operations at the edges of the input would involve only a portion of the filter, resulting in a loss of information.\n",
    "\n",
    "Control Over Output Dimensions: By choosing appropriate padding, you can control the size of the output feature maps after convolution. Valid padding reduces dimensions, while same padding maintains them.\n",
    "\n",
    "Edge Effects Mitigation: Convolutional operations without padding can lead to edge effects where the features at the borders of the input are underrepresented in the output. Padding reduces the impact of these effects.\n",
    "\n",
    "Network Design Flexibility: Padding provides flexibility in designing deep CNN architectures. It allows you to stack multiple convolutional layers without excessive reduction in spatial dimensions, which can help in capturing features at different scales.\n",
    "\n",
    "Convolution Strides: Padding can also influence the choice of convolution stride. With larger strides, padding becomes more important for maintaining feature map dimensions.\n",
    "\n",
    "In summary, padding is a crucial concept in CNNs that involves adding extra pixels or values around the input data before applying convolutional operations. It plays a significant role in preserving spatial information, controlling output dimensions, mitigating edge effects, and providing design flexibility for deep networks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8658b0-a3cf-4117-a33a-bf1df115fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" compare zeco-padding and valid-padding in tecXs oj theic ejjects on the output\n",
    "featuce Xap size. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4616a9c8-0f35-4c96-81bc-266c257e1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Zero Padding (also known as \"Same\" Padding):\n",
    "Zero padding involves adding zeros (or any constant value) around the input data before performing a convolution operation. The added zeros create a border around the input, allowing the convolutional filters to fully cover the input, including its edges. This is particularly useful to prevent the loss of information at the borders during convolution.\n",
    "\n",
    "Effect on Output Feature Map Size:\n",
    "When using zero padding, the output feature map size can be maintained to be the same as the input feature map size (hence the term \"same\" padding). This is achieved by adjusting the size of the padding such that the convolutional operation doesn't alter the spatial dimensions.\n",
    "\n",
    "\n",
    "Valid Padding:\n",
    "Valid padding involves applying a convolutional filter only to positions where the filter fully overlaps with the input data, without any extra padding. This means that the filter's center is aligned with positions in the input where it can fit entirely without extending beyond the input boundaries.\n",
    "\n",
    "Effect on Output Feature Map Size:\n",
    "With valid padding, the convolution operation is only performed where the filter completely fits within the input. As a result, the output feature map size will be smaller than the input feature map size. The exact reduction in size depends on the size of the filter and the convolution stride.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edaef95-fa6f-4a59-b8d5-6e9c55eebc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Provide  ovecview oj LeNet-5 acchitecture\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf266b-3bca-4a5b-9aeb-96f5da172761",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LeNet-5 is a pioneering convolutional neural network (CNN) architecture designed by Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner in 1998. It was one of the first successful CNN architectures and played a significant role in shaping the development of deep learning for image recognition tasks. LeNet-5 was primarily designed for handwritten digit recognition and was widely used for recognizing characters on checks and other similar documents. Here's an overview of the LeNet-5 architecture:\n",
    "\n",
    "Architecture Overview:\n",
    "LeNet-5 consists of seven layers, including three convolutional layers followed by two fully connected layers and two subsampling (pooling) layers. The architecture can be summarized as follows:\n",
    "\n",
    "Input Layer: The network takes grayscale images of size 32x32 pixels as input. Unlike modern architectures, LeNet-5 doesn't normalize the pixel values to a specific range (e.g., [0, 1]).\n",
    "\n",
    "Convolutional Layer 1: The first convolutional layer has 6 feature maps (also known as channels), each obtained by applying a convolution operation using a 5x5 filter with a stride of 1. This is followed by a sigmoid activation function.\n",
    "\n",
    "Subsampling (Pooling) Layer 1: This layer performs 2x2 max pooling on each feature map, reducing the spatial dimensions by half. Max pooling selects the maximum value from each 2x2 region.\n",
    "\n",
    "Convolutional Layer 2: The second convolutional layer has 16 feature maps, also obtained using 5x5 filters with a stride of 1 and followed by a sigmoid activation.\n",
    "\n",
    "Subsampling (Pooling) Layer 2: Similar to the first pooling layer, this layer performs 2x2 max pooling to further reduce spatial dimensions.\n",
    "\n",
    "Fully Connected Layer 1: This layer has 120 neurons, each connected to all the activations from the previous subsampling layer. It serves as a bridge between the convolutional layers and the final classification layer.\n",
    "\n",
    "Fully Connected Layer 2 (Output Layer): The last fully connected layer has 84 neurons, followed by a softmax activation layer with 10 output neurons. The 10 output neurons correspond to the 10 possible classes (digits 0-9) in the case of digit recognition.\n",
    "\n",
    "Activation Function:\n",
    "LeNet-5 primarily uses the sigmoid activation function for the convolutional and fully connected layers, with a softmax activation in the output layer for classification.\n",
    "\n",
    "Significance:\n",
    "LeNet-5 was groundbreaking in its time as it demonstrated the effectiveness of deep learning for image recognition tasks. While its architecture is relatively simple compared to modern CNNs, it introduced several key concepts that are still relevant today, such as the use of convolutional layers, pooling layers, and fully connected layers in a hierarchical manner. LeNet-5 paved the way for more complex architectures that followed, like AlexNet, VGG, and ResNet, and contributed to the resurgence of interest in neural networks and deep learning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811cfd7-5a5d-4242-b3ff-35d422ea62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Desccire the key components of LeNet-5 and their respective purposes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06324a85-1105-43b4-bdfa-d5e0da9a44e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Certainly! LeNet-5 consists of several key components, each serving a specific purpose in the architecture. Let's go through these components and their respective purposes:\n",
    "\n",
    "1. Input Layer:\n",
    "\n",
    "Purpose: Accepts input images with dimensions of 32x32 pixels.\n",
    "Function: Passes the input image to the subsequent layers for feature extraction and classification.\n",
    "2. Convolutional Layers (Convolution + Sigmoid Activation):\n",
    "\n",
    "Purpose: Extracts features from the input image using convolution operations.\n",
    "Function: Each convolutional layer applies a set of filters to the input, capturing different features like edges, textures, and patterns.\n",
    "Sigmoid Activation: The sigmoid activation function introduces non-linearity and helps capture complex relationships within the data.\n",
    "3. Subsampling (Pooling) Layers (Max Pooling):\n",
    "\n",
    "Purpose: Reduces spatial dimensions and enhances translation invariance.\n",
    "Function: Performs max pooling, selecting the maximum value from local regions of the feature maps.\n",
    "Result: Reduces the size of the feature maps while retaining dominant features.\n",
    "4. Fully Connected Layers:\n",
    "\n",
    "Purpose: Combines features learned from convolutional and pooling layers for classification.\n",
    "Function: Each neuron in the fully connected layers is connected to all activations from the previous layer, enabling the network to learn high-level abstractions.\n",
    "FC Layer 1 (120 neurons): Captures more complex features by combining lower-level features.\n",
    "FC Layer 2 (Output Layer, 84 neurons): Prepares the network for classification and outputs a feature vector for each class.\n",
    "5. Softmax Activation Layer (Output Layer):\n",
    "\n",
    "Purpose: Produces class probabilities for classification.\n",
    "Function: Applies the softmax activation function to the outputs of the previous layer, converting them into probabilities that indicate the likelihood of each class.\n",
    "Result: The class with the highest probability is predicted as the final output.\n",
    "In summary, the key components of LeNet-5 and their purposes are as follows:\n",
    "\n",
    "Input Layer: Accepts input images.\n",
    "Convolutional Layers: Extracts features using convolution and sigmoid activation.\n",
    "Subsampling (Pooling) Layers: Reduces spatial dimensions using max pooling.\n",
    "Fully Connected Layers: Combines and learns complex features for classification.\n",
    "Softmax Activation Layer (Output Layer): Produces class probabilities for classification.\n",
    "These components work in concert to transform raw input images into meaningful feature representations and make predictions about the classes of the input images. LeNet-5's architecture was pivotal in showcasing the potential of deep learning for image recognition tasks and laid the foundation for more advanced CNN architectures.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a50cb-c713-48d1-a40b-716566174e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Discuss the advantages and limitations of LeNet-5 in the context oj image classijication tasks \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c6032-4232-4db8-84a3-9f1b3987e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LeNet-5 was a pioneering architecture in the field of convolutional neural networks (CNNs) and played a significant role in advancing image classification tasks. However, like any model, it has its own set of advantages and limitations when applied to image classification tasks. Let's explore these aspects:\n",
    "\n",
    "Advantages of LeNet-5 for Image Classification:\n",
    "\n",
    "Simplicity and Effectiveness: LeNet-5 demonstrated that deep learning architectures can effectively learn hierarchical features from images for classification tasks, even with a relatively simple design.\n",
    "\n",
    "Feature Extraction: The use of convolutional layers allows LeNet-5 to automatically extract features like edges, textures, and patterns from input images. This hierarchical feature extraction makes it suitable for a wide range of image classification problems.\n",
    "\n",
    "Translation Invariance: The inclusion of max pooling layers helps LeNet-5 achieve translation invariance, making it robust to slight shifts or translations of objects within images.\n",
    "\n",
    "Early Success: LeNet-5's success in handwritten digit recognition tasks, especially on the MNIST dataset, highlighted the potential of deep learning for image recognition and classification.\n",
    "\n",
    "Learning Hierarchies: By stacking convolutional and pooling layers, LeNet-5 captures increasingly abstract features, which enables it to learn hierarchical representations of input images.\n",
    "\n",
    "Limitations of LeNet-5 for Image Classification:\n",
    "\n",
    "Limited Complexity: LeNet-5's architecture is relatively simple compared to modern CNN architectures. It may struggle with more complex and nuanced patterns present in real-world images.\n",
    "\n",
    "Small Receptive Fields: The 5x5 filter size in the convolutional layers limits the receptive field for capturing large-scale features, which might be essential for recognizing larger objects.\n",
    "\n",
    "Lack of Non-Linearity: LeNet-5 primarily uses the sigmoid activation function, which can suffer from the vanishing gradient problem. Modern architectures often use rectified linear units (ReLU) for better training convergence.\n",
    "\n",
    "Limited to Small Images: LeNet-5 was designed for 32x32 pixel images, making it less suitable for high-resolution images commonly encountered today.\n",
    "\n",
    "Not Designed for Complex Tasks: While LeNet-5 was successful for digit recognition, it might struggle with more complex and diverse datasets like ImageNet, which contain a wider variety of objects.\n",
    "\n",
    "Overfitting: Like any model, LeNet-5 can be prone to overfitting, especially on smaller datasets. Regularization techniques were less advanced during its time.\n",
    "\n",
    "Limited Training Techniques: Training deep models was relatively challenging when LeNet-5 was introduced. Modern techniques such as dropout, batch normalization, and advanced optimization algorithms were not part of its original design.\n",
    "\n",
    "In summary, LeNet-5 was groundbreaking in demonstrating the power of CNNs for image classification, particularly for handwritten digit recognition. While it has limitations compared to modern architectures, its fundamental concepts paved the way for the development of more advanced CNNs that are capable of handling diverse and complex image classification tasks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d8a07-18cf-4e7d-8f02-c797197441d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implement LeNet-5 using a deep learning framework oy youc choice (e.g., TensocFlow, P¢Tocch) and tcain it on a purlicl¢ availarle dataset (e.g., MNIST). Evaluate its pecjocXance and pcovide\n",
    "insights.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8debbb19-d144-4bc5-ae77-b1d3df33e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 10:07:06.996587: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-11 10:07:07.072652: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-11 10:07:07.074623: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-11 10:07:08.364678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b21a372-961d-418e-9922-bd7d8a79e254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.13)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.57.0 keras-2.13.1 libclang-16.0.6 markdown-3.4.4 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.33.0 termcolor-2.3.0 werkzeug-2.3.6 wrapt-1.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42d3666-6e5d-4a97-ae3f-a08f649e74f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfec7aaa-4613-47cb-84ff-8e499c555795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 6)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 16)          2416      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               30840     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44426 (173.54 KB)\n",
      "Trainable params: 44426 (173.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120, activation='relu'))\n",
    "model.add(layers.Dense(84, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd45d0b-7b2c-4cb0-8557-83894aabfbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.2250 - accuracy: 0.9314 - val_loss: 0.0722 - val_accuracy: 0.9771\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.0711 - accuracy: 0.9778 - val_loss: 0.0565 - val_accuracy: 0.9817\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0520 - accuracy: 0.9836 - val_loss: 0.0592 - val_accuracy: 0.9793\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.0390 - val_accuracy: 0.9875\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.0423 - val_accuracy: 0.9874\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.0497 - val_accuracy: 0.9854\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.0457 - val_accuracy: 0.9861\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.0428 - val_accuracy: 0.9866\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0410 - val_accuracy: 0.9887\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0395 - val_accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a901b73-910f-4107-8942-05b8a359e23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9887\n",
      "Test accuracy: 0.9886999726295471\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc12ef4-39c8-4a60-9704-4f4c08514b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f8eaa-b8e1-4775-a619-4f116196f8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad78839-fef2-4637-998d-9fdae35e16da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
