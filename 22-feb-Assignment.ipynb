{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15beb069-c7cb-4d3b-92a1-bdb49805c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98409c-e0f3-4453-aac3-51424d28055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the PW-Foundation YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and get the HTML response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML response using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the links to the video pages\n",
    "video_links = soup.find_all(\"a\", {\"class\": \"yt-simple-endpoint style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the video URLs of the first five videos\n",
    "video_urls = []\n",
    "for i in range(5):\n",
    "    video_url = \"https://www.youtube.com\" + video_links[i][\"href\"]\n",
    "    video_urls.append(video_url)\n",
    "\n",
    "# Print the video URLs\n",
    "print(video_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69246aa3-147d-4ffc-aefd-3eb3a84daef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f6356-41f8-4393-a729-1938df90cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the PW-Foundation YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and get the HTML response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML response using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the div elements containing video thumbnails\n",
    "thumbnail_divs = soup.find_all(\"div\", {\"class\": \"style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the thumbnail URLs of the first five videos\n",
    "thumbnail_urls = []\n",
    "for i in range(5):\n",
    "    thumbnail_url = thumbnail_divs[i].find(\"img\")[\"src\"]\n",
    "    thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "# Print the thumbnail URLs\n",
    "print(thumbnail_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b55e1-d7d3-4af8-a62f-049565125391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a6d42-d854-46b9-a0b0-6d153073f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the PW-Foundation YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and get the HTML response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML response using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the div elements containing video titles\n",
    "title_divs = soup.find_all(\"div\", {\"class\": \"style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the titles of the first five videos\n",
    "titles = []\n",
    "for i in range(5):\n",
    "    title = title_divs[i].find(\"a\", {\"id\": \"video-title\"})[\"title\"]\n",
    "    titles.append(title)\n",
    "\n",
    "# Print the titles\n",
    "print(titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080ec94-af12-4d9f-b53c-babc74886419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84798bd8-fa36-4a54-99da-1e1e24d21342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the PW-Foundation YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and get the HTML response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML response using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the div elements containing video views\n",
    "view_divs = soup.find_all(\"div\", {\"class\": \"style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the number of views of the first five videos\n",
    "views = []\n",
    "for i in range(5):\n",
    "    view_string = view_divs[i].find(\"span\", {\"class\": \"style-scope ytd-grid-video-renderer\"}).text.strip()\n",
    "    view_number = int(''.join(filter(str.isdigit, view_string)))\n",
    "    views.append(view_number)\n",
    "\n",
    "# Print the number of views\n",
    "print(views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8146bb4-227e-48ec-a182-9b8b864d8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97bfdff-23e2-4874-931b-02251f935213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the PW-Foundation YouTube channel\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL and get the HTML response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML response using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the div elements containing video times\n",
    "time_divs = soup.find_all(\"div\", {\"class\": \"style-scope ytd-grid-video-renderer\"})\n",
    "\n",
    "# Extract the time of posting of the first five videos\n",
    "times = []\n",
    "for i in range(5):\n",
    "    time_string = time_divs[i].find(\"span\", {\"class\": \"style-scope ytd-grid-video-renderer\"}).text.strip()\n",
    "    times.append(time_string)\n",
    "\n",
    "# Print the times\n",
    "print(times)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
